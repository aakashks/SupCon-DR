{"cells":[{"cell_type":"markdown","metadata":{"id":"JC-p4CpT1_Lc"},"source":["# Load Data"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T05:12:51.017424Z","iopub.status.busy":"2024-04-16T05:12:51.016653Z","iopub.status.idle":"2024-04-16T05:12:51.028310Z","shell.execute_reply":"2024-04-16T05:12:51.027476Z","shell.execute_reply.started":"2024-04-16T05:12:51.017395Z"},"id":"gr9MjCphpOPx","trusted":true},"outputs":[],"source":["# where we will unpack data\n","# OUTPUT_FOLDER = \"/kaggle/working/\"\n","# DATA_FOLDER = \"/kaggle/input/solfune-satellite/\"\n","# TRAIN_DATA_FOLDER = DATA_FOLDER + 'train/'\n","\n","OUTPUT_FOLDER = \"/scratch/aakash_ks.iitr/dr-scnn/\"\n","DATA_FOLDER = \"/scratch/aakash_ks.iitr/data/diabetic-retinopathy/\"\n","TRAIN_DATA_FOLDER = DATA_FOLDER + 'resized_train/'\n","# TRAIN_DATA_FOLDER = DATA_FOLDER + 'resized_train_c/'\n","\n","# TEST_DATA_FOLDER = DATA_FOLDER + 'test/'"]},{"cell_type":"markdown","metadata":{"id":"dOaKi5h92DBb"},"source":["# Imports"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:13:45.703815Z","iopub.status.busy":"2024-04-14T16:13:45.703112Z","iopub.status.idle":"2024-04-14T16:13:47.998744Z","shell.execute_reply":"2024-04-14T16:13:47.997755Z","shell.execute_reply.started":"2024-04-14T16:13:45.703785Z"},"id":"NNdj2cxdkpiv","trusted":true},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","\n","from PIL import Image"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:13:48.000701Z","iopub.status.busy":"2024-04-14T16:13:48.000307Z","iopub.status.idle":"2024-04-14T16:13:55.723296Z","shell.execute_reply":"2024-04-14T16:13:55.722301Z","shell.execute_reply.started":"2024-04-14T16:13:48.000675Z"},"id":"7yoCqGCB2jIS","trusted":true},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","\n","from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n","from torchvision.transforms import v2\n","\n","import timm"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T05:18:58.885632Z","iopub.status.busy":"2024-04-16T05:18:58.884804Z","iopub.status.idle":"2024-04-16T05:18:58.891553Z","shell.execute_reply":"2024-04-16T05:18:58.890585Z","shell.execute_reply.started":"2024-04-16T05:18:58.885598Z"},"id":"8Ejzj4rDx_GK","trusted":true},"outputs":[],"source":["\n","NUM_CLASSES = 5\n","\n","class CFG:\n","    seed = 29\n","    N_folds = 5\n","    train_folds = [0] # [0,1,2,3,4]\n","\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    apex=True # use half precision\n","\n","    # model_name = \"maxvit_tiny_tf_512\"\n","    model_name = \"resnet50.a1_in1k\"\n","    epochs = 20\n","    cropped = False\n","    # weights =  torch.tensor([0.206119, 0.793881],dtype=torch.float32)\n","\n","    clip_val = 1000.\n","    batch_size = 64\n","    # gradient_accumulation_steps = 1\n","\n","    lr = 1e-4\n","    weight_decay=1e-2\n","    \n","    resolution = 224"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T15:23:54.468659Z","iopub.status.busy":"2024-04-14T15:23:54.468265Z","iopub.status.idle":"2024-04-14T15:24:25.601196Z","shell.execute_reply":"2024-04-14T15:24:25.600218Z","shell.execute_reply.started":"2024-04-14T15:23:54.468630Z"},"trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:naxzo1e2) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">misunderstood-dust-52</strong> at: <a href='https://wandb.ai/aakashks_/hello-world/runs/naxzo1e2/workspace' target=\"_blank\">https://wandb.ai/aakashks_/hello-world/runs/naxzo1e2/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>/scratch/aakash_ks.iitr/dr-scnn/wandb/run-20240512_062748-naxzo1e2/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:naxzo1e2). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.5"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/scratch/aakash_ks.iitr/dr-scnn/wandb/run-20240512_063500-tbkrxvyv</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/aakashks_/hello-world/runs/tbkrxvyv/workspace' target=\"_blank\">zesty-rain-56</a></strong> to <a href='https://wandb.ai/aakashks_/hello-world' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/aakashks_/hello-world' target=\"_blank\">https://wandb.ai/aakashks_/hello-world</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/aakashks_/hello-world/runs/tbkrxvyv/workspace' target=\"_blank\">https://wandb.ai/aakashks_/hello-world/runs/tbkrxvyv/workspace</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import wandb\n","# from kaggle_secrets import UserSecretsClient\n","# user_secrets = UserSecretsClient()\n","# wandb.login(key=user_secrets.get_secret(\"wandb_api\"))\n","\n","run = wandb.init(\n","    project=\"hello-world\", \n","    dir=OUTPUT_FOLDER,\n","    config={\n","    k:v for k, v in CFG.__dict__.items() if not k.startswith('__')}\n",")"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["device = torch.device(CFG.device)"]},{"cell_type":"markdown","metadata":{"id":"7Ve34id2b7uu"},"source":["# Load train data"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:13:55.725554Z","iopub.status.busy":"2024-04-14T16:13:55.725188Z","iopub.status.idle":"2024-04-14T16:13:55.745976Z","shell.execute_reply":"2024-04-14T16:13:55.744974Z","shell.execute_reply.started":"2024-04-14T16:13:55.725520Z"},"id":"mq-oqFtvkpix","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>level</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10_left</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10_right</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>13_left</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13_right</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>15_left</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>35121</th>\n","      <td>44347_right</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>35122</th>\n","      <td>44348_left</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>35123</th>\n","      <td>44348_right</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>35124</th>\n","      <td>44349_left</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>35125</th>\n","      <td>44349_right</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>35126 rows × 2 columns</p>\n","</div>"],"text/plain":["             image  level\n","0          10_left      0\n","1         10_right      0\n","2          13_left      0\n","3         13_right      0\n","4          15_left      1\n","...            ...    ...\n","35121  44347_right      0\n","35122   44348_left      0\n","35123  44348_right      0\n","35124   44349_left      0\n","35125  44349_right      1\n","\n","[35126 rows x 2 columns]"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["train_data = pd.read_csv(os.path.join(DATA_FOLDER, 'trainLabels.csv'))\n","# train_data = pd.read_csv(os.path.join(DATA_FOLDER, 'trainLabels_cropped.csv'))\n","train_data"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"data":{"text/plain":["35126"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["# remove all images from the csv if they are not in the folder\n","lst = map(lambda x: x[:-5], os.listdir(TRAIN_DATA_FOLDER))\n","train_data = train_data[train_data.image.isin(lst)]\n","len(train_data)"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"data":{"text/plain":["level\n","0    25810\n","2     5292\n","1     2443\n","3      873\n","4      708\n","Name: count, dtype: int64"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["train_data.level.value_counts()"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"data":{"text/plain":["level\n","0    10\n","1    10\n","2    10\n","4    10\n","3    10\n","Name: count, dtype: int64"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["# take only 100 samples from each class\n","train_data = train_data.groupby('level').head(1000).reset_index(drop=True)\n","train_data.level.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"1Mu24W3Xkpix"},"source":["# Dataset"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":["from torchvision.transforms import functional as func\n","\n","class CustomTransform:\n","    def __init__(self, output_size=(CFG.resolution, CFG.resolution), radius_factor=0.9):\n","        self.output_size = output_size\n","        self.radius_factor = radius_factor\n","\n","    def __call__(self, img):\n","        # Assuming img is a PIL Image\n","        # Normalize and preprocess as previously defined\n","        img = func.resize(img, int(min(img.size) / self.radius_factor))\n","        img_tensor = func.to_tensor(img)\n","        mean, std = img_tensor.mean([1, 2]), img_tensor.std([1, 2])\n","        img_normalized = func.normalize(img_tensor, mean.tolist(), std.tolist())\n","        kernel_size = 15\n","        padding = kernel_size // 2\n","        avg_pool = torch.nn.AvgPool2d(kernel_size, stride=1, padding=padding)\n","        local_avg = avg_pool(img_normalized.unsqueeze(0)).squeeze(0)\n","        img_subtracted = img_normalized - local_avg\n","        center_crop_size = int(min(img_subtracted.shape[1:]) * self.radius_factor)\n","        img_cropped = func.center_crop(img_subtracted, [center_crop_size, center_crop_size])\n","\n","        # Apply augmentations\n","        img_resized = func.resize(img_cropped, self.output_size)\n","\n","        return img_resized"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:14:03.100814Z","iopub.status.busy":"2024-04-14T16:14:03.100062Z","iopub.status.idle":"2024-04-14T16:14:03.108402Z","shell.execute_reply":"2024-04-14T16:14:03.107471Z","shell.execute_reply.started":"2024-04-14T16:14:03.100781Z"},"trusted":true},"outputs":[],"source":["# train_transforms = CustomTransform()\n","\n","train_transforms = v2.Compose([\n","    CustomTransform(),\n","    # v2.RandomResizedCrop(CFG.resolution, scale=(0.8, 1.0)),  # Krizhevsky style random cropping\n","    v2.RandomHorizontalFlip(),  # Random horizontal flip\n","    v2.RandomVerticalFlip(),  # Random vertical flip\n","    v2.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2)),  # Gaussian blur with random kernel size and sigma\n","    v2.RandomRotation(degrees=(0, 90)),  # Random rotation between 0 and 360 degrees\n","    v2.ToDtype(torch.float32, scale=False),\n","])\n","\n","val_transforms = v2.Compose([\n","    CustomTransform(),\n","    v2.ToDtype(torch.float32, scale=False),\n","])"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:34.766966Z","iopub.status.busy":"2024-04-14T16:21:34.766584Z","iopub.status.idle":"2024-04-14T16:21:34.774717Z","shell.execute_reply":"2024-04-14T16:21:34.773808Z","shell.execute_reply.started":"2024-04-14T16:21:34.766935Z"},"id":"_mAcIdn2kpiy","scrolled":true,"trusted":true},"outputs":[],"source":["class ImageTrainDataset(Dataset):\n","    def __init__(\n","        self,\n","        folder,\n","        data,\n","        transforms,\n","    ):\n","        self.folder = folder\n","        self.data = data\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        d = self.data.loc[index]\n","        image = Image.open(f\"{self.folder}{d.image}.jpeg\")\n","        image = self.transforms(image)\n","        label = d.level\n","\n","        return image, torch.tensor(label, dtype=torch.long)"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["# # visualize the transformations\n","# train_dataset = ImageTrainDataset(TRAIN_DATA_FOLDER, train_data, train_transforms)\n","# image, label = train_dataset[10]\n","# transformed_img_pil = func.to_pil_image(image)\n","# plt.imshow(transformed_img_pil)"]},{"cell_type":"markdown","metadata":{"id":"OzgB1JpAv3qg"},"source":["# Metric"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:35.200919Z","iopub.status.busy":"2024-04-14T16:21:35.200562Z","iopub.status.idle":"2024-04-14T16:21:35.205583Z","shell.execute_reply":"2024-04-14T16:21:35.204624Z","shell.execute_reply.started":"2024-04-14T16:21:35.200892Z"},"id":"WNxSAhBrxJ-G","trusted":true},"outputs":[],"source":["from sklearn.metrics import f1_score as sklearn_f1\n","from sklearn.metrics import confusion_matrix, roc_auc_score"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:35.486917Z","iopub.status.busy":"2024-04-14T16:21:35.486197Z","iopub.status.idle":"2024-04-14T16:21:35.493226Z","shell.execute_reply":"2024-04-14T16:21:35.492187Z","shell.execute_reply.started":"2024-04-14T16:21:35.486887Z"},"id":"n0u9VgXTv7VU","trusted":true},"outputs":[],"source":["# def find_best_threshold(targets, predictions):\n","#     score_5 = sklearn_f1(targets, predictions > 0.5)\n","#     best_score = 0\n","#     best_th = -1\n","#     for i in range(100):\n","#         threshold =  i/100\n","#         _score = sklearn_f1(targets, predictions > threshold)\n","#         if _score > best_score:\n","#             best_score = _score\n","#             best_th = threshold\n","\n","#     tn, fp, fn, tp = confusion_matrix(targets.numpy(), predictions.numpy() > best_th).ravel()\n","#     print(f\"tp: {tp}, tn: {tn}, fp: {fp}, fn: {fn}\")\n","#     return score_5, best_score, best_th"]},{"cell_type":"markdown","metadata":{"id":"Zyfw9PLdkpiz"},"source":["# Train and evaluate functions"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["class style:\n","    BLUE = '\\033[94m'\n","    GREEN = '\\033[92m'\n","    YELLOW = '\\033[93m'\n","    END = '\\033[0m'\n","    BOLD = '\\033[1m'"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:36.151872Z","iopub.status.busy":"2024-04-14T16:21:36.151533Z","iopub.status.idle":"2024-04-14T16:21:36.156966Z","shell.execute_reply":"2024-04-14T16:21:36.155985Z","shell.execute_reply.started":"2024-04-14T16:21:36.151847Z"},"id":"KKt67LPn9YtB","trusted":true},"outputs":[],"source":["def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:36.353134Z","iopub.status.busy":"2024-04-14T16:21:36.352777Z","iopub.status.idle":"2024-04-14T16:21:36.363087Z","shell.execute_reply":"2024-04-14T16:21:36.362142Z","shell.execute_reply.started":"2024-04-14T16:21:36.353107Z"},"id":"yXcFJ6IYkpiz","trusted":true},"outputs":[],"source":["def evaluate_model(cfg, model, data_loader, loss_criterion, epoch=-1):\n","    # loss_fn = nn.CrossEntropyLoss(weight=cfg.weights.to(device), label_smoothing=0.1)\n","    loss_fn = loss_criterion\n","\n","    model.eval()\n","    val_loss = 0\n","\n","    targets = []\n","    predictions = []\n","\n","    total_len = len(data_loader)\n","    tk0 = tqdm(enumerate(data_loader), total=total_len)\n","    for step, (images, labels) in tk0:\n","        images = images.to(device)\n","        target = labels.to(device)\n","\n","        with torch.no_grad():\n","            logits = model(images)\n","\n","        loss = loss_fn(logits, target)\n","        val_loss += loss.item()\n","\n","        targets.append(target.detach().cpu())\n","        predictions.append(logits.detach().cpu())\n","        del images, target, logits\n","\n","    targets = torch.cat(targets, dim=0)\n","    predictions = torch.cat(predictions, dim=0)\n","    predictions = F.softmax(predictions, dim=1)\n","\n","    val_loss /= total_len\n","    # base_score, best_score, best_th = find_best_threshold(targets, predictions[:, 1])\n","    roc_auc = roc_auc_score(targets.numpy(), predictions.numpy(), multi_class='ovo')\n","    # roc_auc = 1\n","\n","    print(f'Epoch {epoch} validation loss = {val_loss:.4f} auc = {roc_auc:.4f}')\n","    return val_loss, roc_auc"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:36.532561Z","iopub.status.busy":"2024-04-14T16:21:36.532193Z","iopub.status.idle":"2024-04-14T16:21:36.545367Z","shell.execute_reply":"2024-04-14T16:21:36.544346Z","shell.execute_reply.started":"2024-04-14T16:21:36.532533Z"},"id":"nZFniP2hkpi0","trusted":true},"outputs":[],"source":["\n","def train_epoch(cfg, model, train_loader, loss_criterion, optimizer, scheduler, epoch):\n","    scaler = torch.cuda.amp.GradScaler(enabled=cfg.apex)\n","    # loss_fn = nn.CrossEntropyLoss(weight=cfg.weights.to(device), label_smoothing=0.1)\n","    loss_fn = loss_criterion\n","\n","    model.train()\n","    train_loss = 0\n","    learning_rate_history = []\n","\n","    targets = []\n","    predictions = []\n","\n","    total_len = len(train_loader)\n","    tk0 = tqdm(enumerate(train_loader), total=total_len)\n","    for step, (images, labels) in tk0:\n","        images = images.to(device, non_blocking=True)\n","        target = labels.to(device, non_blocking=True)\n","\n","        # https://pytorch.org/blog/accelerating-training-on-nvidia-gpus-with-pytorch-automatic-mixed-precision/\n","        with torch.cuda.amp.autocast(enabled=cfg.apex):\n","            logits = model(images)\n","            loss = loss_fn(logits, target)\n","\n","        scaler.scale(loss).backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=cfg.clip_val)\n","\n","        train_loss += loss.item()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        optimizer.zero_grad()\n","\n","        if scheduler is None:\n","            lr = optimizer.param_groups[0]['lr']\n","        else:\n","            scheduler.step()\n","            lr = scheduler.get_last_lr()[0]\n","\n","        tk0.set_description(f\"Epoch {epoch} training {step+1}/{total_len} [LR {lr:0.6f}] - loss: {train_loss/(step+1):.4f}\")\n","        learning_rate_history.append(lr)\n","\n","        targets.append(target.detach().cpu())\n","        predictions.append(logits.detach().cpu())\n","        del images, target\n","\n","    targets = torch.cat(targets, dim=0)\n","    predictions = torch.cat(predictions, dim=0)\n","    predictions = F.softmax(predictions, dim=1)\n","\n","    train_loss /= total_len\n","    roc_auc = roc_auc_score(targets.numpy(), predictions.numpy(), multi_class='ovo')\n","    # roc_auc = 1\n","\n","    print(f'Epoch {epoch} train loss = {train_loss:.4f}, auc = {roc_auc:.4f}')\n","    return train_loss, learning_rate_history, roc_auc"]},{"cell_type":"markdown","metadata":{"id":"qN83vJk4xCA3"},"source":["# Train model"]},{"cell_type":"markdown","metadata":{"id":"8NyHYtzwZT8h"},"source":["## Split data\n","\n","The distribution of classes in the training data is not balance so using StratifiedKFold will ensure that the distrubution of positive and negative samples in all folds will match the original distributions."]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:39.039930Z","iopub.status.busy":"2024-04-14T16:21:39.039564Z","iopub.status.idle":"2024-04-14T16:21:39.307011Z","shell.execute_reply":"2024-04-14T16:21:39.306082Z","shell.execute_reply.started":"2024-04-14T16:21:39.039904Z"},"id":"HaYXa749AEes","outputId":"65b6c941-0e6e-4503-b513-574264d657ce","trusted":true},"outputs":[],"source":["# plt.figure(figsize=(4,2))\n","# sns.histplot(train_data[\"label\"])"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:39.309571Z","iopub.status.busy":"2024-04-14T16:21:39.308889Z","iopub.status.idle":"2024-04-14T16:21:39.321211Z","shell.execute_reply":"2024-04-14T16:21:39.320264Z","shell.execute_reply.started":"2024-04-14T16:21:39.309534Z"},"id":"DRHeo8pr56FX","trusted":true},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","\n","sgkf = StratifiedKFold(n_splits=CFG.N_folds, random_state=CFG.seed, shuffle=True)\n","for i, (train_index, test_index) in enumerate(sgkf.split(train_data[\"image\"].values, train_data[\"level\"].values)):\n","    train_data.loc[test_index, \"fold\"] = i"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:39.448281Z","iopub.status.busy":"2024-04-14T16:21:39.447697Z","iopub.status.idle":"2024-04-14T16:21:39.484233Z","shell.execute_reply":"2024-04-14T16:21:39.483014Z","shell.execute_reply.started":"2024-04-14T16:21:39.448249Z"},"trusted":true},"outputs":[],"source":["# from torchgeo import models\n","# from torch import nn"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:40.091094Z","iopub.status.busy":"2024-04-14T16:21:40.090402Z","iopub.status.idle":"2024-04-14T16:21:40.096027Z","shell.execute_reply":"2024-04-14T16:21:40.095120Z","shell.execute_reply.started":"2024-04-14T16:21:40.091064Z"},"trusted":true},"outputs":[],"source":["def create_model():\n","    model = timm.create_model(CFG.model_name, in_chans=3, num_classes=NUM_CLASSES, pretrained=True)\n","\n","#     model = models.resnet50(models.ResNet50_Weights.SENTINEL2_ALL_DINO)\n","#     wd = torch.concat([model.conv1.weight[:, :13, ...], model.conv1.weight[:, :7, ...]], dim=1)\n","#     model.conv1 = nn.Conv2d(20, 64, 7, 2, 3, bias=False)\n","#     model.conv1.weight = nn.Parameter(wd)\n","#     model.fc = nn.Linear(in_features=2048, out_features=2, bias=True)\n","\n","    return model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"rF9BFqS8AXBY"},"source":["## Train folds"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:40.983908Z","iopub.status.busy":"2024-04-14T16:21:40.983523Z","iopub.status.idle":"2024-04-14T16:21:48.524465Z","shell.execute_reply":"2024-04-14T16:21:48.523002Z","shell.execute_reply.started":"2024-04-14T16:21:40.983878Z"},"id":"7CFfmp3CxDG5","outputId":"952103d3-bbd9-449f-e9cf-26d5c2608aea","scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model parameters: 23_518_277\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 0 training 1/1 [LR 0.000099] - loss: 1.6123: 100%|████████████████████| 1/1 [00:20<00:00, 20.35s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 0 train loss = 1.6123, auc = 0.4931\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.61s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 0 validation loss = 1.6144 auc = 0.5500\n","\u001b[92mNew best score: 0.0000 -> 0.5500\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 training 1/1 [LR 0.000098] - loss: 1.6053: 100%|████████████████████| 1/1 [00:20<00:00, 20.29s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 train loss = 1.6053, auc = 0.5911\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.56s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 validation loss = 1.6108 auc = 0.5500\n"]},{"name":"stderr","output_type":"stream","text":["\n","Epoch 2 training 1/1 [LR 0.000095] - loss: 1.6139: 100%|████████████████████| 1/1 [00:19<00:00, 19.87s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 train loss = 1.6139, auc = 0.4580\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|                                                                               | 0/1 [00:00<?, ?it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[77], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m train_score_history\u001b[38;5;241m.\u001b[39mappend(train_auc)\n\u001b[1;32m     63\u001b[0m learning_rate_history\u001b[38;5;241m.\u001b[39mextend(train_lr)\n\u001b[0;32m---> 65\u001b[0m val_loss, val_auc \u001b[38;5;241m=\u001b[39m evaluate_model(CFG, model, valid_loader, loss_criterion, epoch)\n\u001b[1;32m     66\u001b[0m val_loss_history\u001b[38;5;241m.\u001b[39mappend(val_loss)\n\u001b[1;32m     67\u001b[0m val_score_history\u001b[38;5;241m.\u001b[39mappend(val_auc)\n","Cell \u001b[0;32mIn[71], line 13\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(cfg, model, data_loader, loss_criterion, epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m total_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_loader)\n\u001b[1;32m     12\u001b[0m tk0 \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(data_loader), total\u001b[38;5;241m=\u001b[39mtotal_len)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (images, labels) \u001b[38;5;129;01min\u001b[39;00m tk0:\n\u001b[1;32m     14\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m     target \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m~/miniconda3/envs/py311/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data()\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1285\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_get_data()\n\u001b[1;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1287\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[0;32m~/miniconda3/envs/py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_queue\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/py311/lib/python3.11/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mwait(remaining)\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n","File \u001b[0;32m~/miniconda3/envs/py311/lib/python3.11/threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mTrue\u001b[39;00m, timeout)\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for FOLD in CFG.train_folds:\n","\n","    seed_everything(CFG.seed)\n","\n","    # PREPARE DATA\n","    fold_train_data = train_data[train_data[\"fold\"] != FOLD].reset_index(drop=True)\n","    fold_valid_data = train_data[train_data[\"fold\"] == FOLD].reset_index(drop=True)\n","\n","    # display(\n","    #     pd.merge(\n","    #         fold_valid_data.groupby(by=[\"label\"])[\"file_name\"].count().rename(\"valid\").reset_index(),\n","    #         fold_train_data.groupby(by=[\"label\"])[\"file_name\"].count().rename(\"train\").reset_index(),\n","    #          on=\"label\", how=\"left\").T,)\n","\n","\n","    train_dataset = ImageTrainDataset(TRAIN_DATA_FOLDER, fold_train_data, transforms=train_transforms)\n","    valid_dataset = ImageTrainDataset(TRAIN_DATA_FOLDER, fold_valid_data, transforms=val_transforms)\n","\n","    train_loader = DataLoader(\n","            train_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=True,\n","            num_workers=16,\n","            pin_memory=True,\n","            drop_last=True\n","        )\n","\n","    valid_loader = DataLoader(\n","        valid_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=16,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # PREPARE MODEL, OPTIMIZER AND SCHEDULER\n","    model = create_model()\n","    print(f\"Model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):_}\")\n","\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n","        optimizer, eta_min=1e-6, T_max =CFG.epochs * len(train_loader),\n","        )\n","    \n","    loss_criterion = nn.CrossEntropyLoss()\n","\n","    # TRAIN FOLD\n","    learning_rate_history = []\n","    train_loss_history = []\n","    train_score_history = []\n","    val_loss_history = []\n","    val_score_history = []\n","\n","    best_score = 0\n","    \n","    wandb.run.tags = [f\"fold_{FOLD}\"]\n","    \n","    for epoch in range(0, CFG.epochs):\n","        train_loss, train_lr, train_auc = train_epoch(CFG, model, train_loader, loss_criterion, optimizer, scheduler, epoch)\n","        train_loss_history.append(train_loss)\n","        train_score_history.append(train_auc)\n","        learning_rate_history.extend(train_lr)\n","\n","        val_loss, val_auc = evaluate_model(CFG, model, valid_loader, loss_criterion, epoch)\n","        val_loss_history.append(val_loss)\n","        val_score_history.append(val_auc)\n","        \n","        wandb.log(\n","            {'train': {'loss': train_loss, 'auc': train_auc}, \n","             'val': {'loss': val_loss, 'auc': val_auc}})\n","\n","        if (val_auc > best_score):\n","            print(f\"{style.GREEN}New best score: {best_score:.4f} -> {val_auc:.4f}{style.END}\")\n","            best_score = val_auc\n","            torch.save(model.state_dict(), os.path.join(wandb.run.dir, f'best_model_fold_{FOLD}.pth'))\n","            \n","    # run.log_model(\n","    #     path=os.path.join(wandb.run.dir, 'best_model_fold_{FOLD}'), \n","    #     name=f'{CFG.model_name}_fold_{FOLD}'\n","    # )\n","\n","    # # plot train and validation loss, score and LR\n","    # fig, axes = plt.subplots(1,3, figsize=(12,3))\n","    # axes[0].plot(train_loss_history, label=\"Train\")\n","    # axes[0].plot(val_loss_history, label=\"Valid\")\n","    # axes[0].title.set_text(\"Loss\")\n","    # axes[0].set_xlabel(\"Epoch\")\n","    # axes[0].legend()\n","\n","    # axes[1].plot(train_score_history, label=\"Train\")\n","    # axes[1].plot(val_score_history, label=\"Valid\")\n","    # axes[1].title.set_text(\"F1 score\")\n","    # axes[1].set_xlabel(\"Epoch\")\n","    # axes[1].legend()\n","\n","    # axes[2].plot(learning_rate_history, label=\"LR\")\n","    # axes[2].legend()\n","    # axes[2].title.set_text(\"Learning rate\")\n","    # axes[2].set_xlabel(\"Step\")\n","    # fig.suptitle(f\"Fold {FOLD}\")\n","    # fig.tight_layout()\n","    # plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4568125,"sourceId":7801430,"sourceType":"datasetVersion"},{"datasetId":4568781,"sourceId":7877494,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"08d2c86ce4ab4b9e813473170145d4af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96fb1b36ead648c4a4ebebb74c9fcf2c","placeholder":"​","style":"IPY_MODEL_af10206931434c6fbfde31af25affbfa","value":"model.safetensors: 100%"}},"103798aed0c64914b55a691a4d22253e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4420cb88a6a74540a671a529e7320589","placeholder":"​","style":"IPY_MODEL_6b7cb0c6580d4caba2c4f8385749a145","value":" 124M/124M [00:00&lt;00:00, 384MB/s]"}},"2831af4d288b45b688ba9b5992dce3f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3763df1b6564f319afc8d67073af72f","max":124450218,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4c3f492a9b946a0b72df7ea6bb188a9","value":124450218}},"4420cb88a6a74540a671a529e7320589":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b7cb0c6580d4caba2c4f8385749a145":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87901707be784b03998e8b8093255ea6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96fb1b36ead648c4a4ebebb74c9fcf2c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3763df1b6564f319afc8d67073af72f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4c3f492a9b946a0b72df7ea6bb188a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af10206931434c6fbfde31af25affbfa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b53d0ba4ae3e496092fdf021cb4097aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08d2c86ce4ab4b9e813473170145d4af","IPY_MODEL_2831af4d288b45b688ba9b5992dce3f4","IPY_MODEL_103798aed0c64914b55a691a4d22253e"],"layout":"IPY_MODEL_87901707be784b03998e8b8093255ea6"}}}}},"nbformat":4,"nbformat_minor":4}
